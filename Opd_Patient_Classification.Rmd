---
title: "Biomechanical features of orthopedic patients"
author: "Rajeev Kumar Rajesh"
date: "23/08/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This project 'Biomechanical features of orthopedic patients'.In this project each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (each one is a column).

  i)Pelvic incidence
 ii)Pelvic tilt
iii)lumbar lordosis angle
 iv)Sacral slope
  v)Pelvic radius
 vi)Grade of spondylolisthesis
 
We use these biomechanical features to classify patients according to their labels.And also find the correlation between above variable.

```{r}
# Read the csv File
dat <- read.csv("column_2C_weka.csv", stringsAsFactors = F)

```
```{r echo=FALSE}
# Loading all needed libraries

library(knitr)
library(ggplot2)
library(plyr)
library(dplyr)
library(corrplot)
library(caret)
library(gridExtra)
library(scales)
library(Rmisc)
library(ggrepel)
library(randomForest)
library(psych)
library(xgboost)
library(rpart)

```
\newpage

```{r}

head(dat)

dim(dat)

str(dat)

#Total Normal and abnormal people
ggplot(dat,aes(x=class,fill=class))+geom_bar(stat = 'count')+labs(x = 'Number of normal and abnormal peopl') +
  geom_label(stat='count',aes(label=..count..), size=7) +theme_grey(base_size = 18)

table(dat$class)

```


# Analysis of histogram Of all the explanatory variable

```{r}
#Histogram explain all the detail of all six variable

H1<-ggplot(dat,aes(x=pelvic_incidence ))+
  geom_histogram(binwidth = 5, fill='blue')+ theme_grey() +
  scale_x_continuous(breaks= seq(0, 150, by=10))
H2<-ggplot(dat,aes(x=pelvic_tilt.numeric ))+
  geom_histogram(binwidth = 5, fill='blue') + theme_grey() +
  scale_x_continuous(breaks= seq(0, 150, by=10))
H3<-ggplot(dat,aes(x=lumbar_lordosis_angle ))+
  geom_histogram(binwidth = 5, fill='blue') + theme_grey() +
  scale_x_continuous(breaks= seq(0, 150, by=10))
H4<-ggplot(dat,aes(x=sacral_slope ))+
  geom_histogram(binwidth = 5, fill='blue') + theme_grey() +
  scale_x_continuous(breaks= seq(0, 150, by=10))
H5<-ggplot(dat,aes(x=pelvic_radius ))+
  geom_histogram(binwidth = 5, fill='blue') + theme_grey() +
  scale_x_continuous(breaks= seq(0, 150, by=10))
H6<-ggplot(dat,aes(x=degree_spondylolisthesis ))+
  geom_histogram(binwidth = 5, fill='blue') + theme_grey() 
grid.arrange(H1,H2,H3,H4,H5,H6)


set.seed(1, sample.kind = 'Rounding')
library(rpart)
arbre <- rpart(dat$class~., method="class", minsplit=150, xval=10000, data=dat)
plot(arbre, uniform=TRUE, margin=0.1, main="Decision Tree")
text(arbre, fancy=TRUE, use.n=TRUE, pretty=0, all=TRUE)

```


We find that those with inferior spondylolisthesis at 14.85 are those of patients who are fortunate enough to have normal class,but it should be noted that it is normal that when pelvic_radius is supperieur or equal to 125.

```{r}
#We can also view it on the boxplot.
ggplot(dat,aes(x=factor(class),y=degree_spondylolisthesis))+geom_boxplot()

```


We can also visualize the density of the set of variables of importance that explains the class of patients.

```{r}


D1<-ggplot(dat,aes(x=degree_spondylolisthesis,fill=class))+
  geom_density(alpha=0.5, aes(fill=factor(class))) + 
  labs(title="degree spondylolisthesis")  + theme_grey()
D2<-ggplot(dat,aes(x=pelvic_tilt.numeric,fill=class))+ 
  geom_density(alpha=0.5, aes(fill=factor(class))) + 
  labs(title="pelvic tilt")  + theme_grey()
D3<-ggplot(dat,aes(x=lumbar_lordosis_angle,fill=class))+ 
  geom_density(alpha=0.5, aes(fill=factor(class))) + 
  labs(title="lumbar lordosis angle") + theme_grey()
D4<-ggplot(dat,aes(x=sacral_slope,fill=class))+ 
  geom_density(alpha=0.5, aes(fill=factor(class))) + labs(title="sacral slope") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + theme_grey()
D5<-ggplot(dat,aes(x=pelvic_radius,fill=class))+ 
  geom_density(alpha=0.5, aes(fill=factor(class))) + 
  labs(title="pelvic radius") + theme_grey()
D6<-ggplot(dat,aes(x=degree_spondylolisthesis,fill=class))+ 
  geom_density(alpha=0.5, aes(fill=factor(class))) + 
  labs(title="grade of spondylolisthesis") + theme_grey()
grid.arrange(D1,D2,D3,D4,D5,D6)

#Below is the boxplot of all variables
B1<-ggplot(dat,aes(x=factor(class),y=pelvic_incidence ))+geom_boxplot()
B2<-ggplot(dat,aes(x=factor(class),y=pelvic_tilt.numeric))+geom_boxplot()
B3<-ggplot(dat,aes(x=factor(class),y=lumbar_lordosis_angle))+geom_boxplot()
B4<-ggplot(dat,aes(x=factor(class),y=sacral_slope))+geom_boxplot()
B5<-ggplot(dat,aes(x=factor(class),y=pelvic_radius))+geom_boxplot()
B6<-ggplot(dat,aes(x=factor(class),y=degree_spondylolisthesis))+geom_boxplot()
grid.arrange(B1,B2,B3,B4,B5,B6)

```

# Correlation between variables
  For this part we are interested in the correlation of numeric variables to better understand 
  their evolution between, we will take degree spondylolisthesis as target. Altogether, there 
  all numeric variables with a correlation greater than zero with degree spondylolisthesis .



```{r}
library(corrplot)
numericVars <- which(sapply(dat, is.numeric)) #index vector numeric variables
dat_numVar <- dat[, numericVars]
cor_numVar <- cor(dat_numVar, use="pairwise.complete.obs") #correlations of all numeric variables
#sort on decreasing correlations with degree_spondylolisthesis
cor_sorted <- as.matrix(sort(cor_numVar[,'degree_spondylolisthesis'], decreasing = TRUE))
#select only high corelations
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]
corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7)
```


We notice that,there are 3 numeric variables with a correlation of at least 0.5 with degree_spondylolisthesis,and there is no correlation between pelvic_radius and degree_spondylolisthesis.It also becomes clear the multicollinearity is an issue. For example: the correlation between sacral_slope and pelvic_incidence is very high (0.81), and both have similar (high) correlations with degree_spondylolisthesis. Now let us visualize the correlation of these variables with respect to our target before visualizing that of sacral_slope and pelvic_incidence.

#  Now we analyze the relationship between degree spondylolisthesis And rest of the other Variables 
   
   
```{r}
library(gridExtra)
s1<-ggplot(data=dat, aes(x=pelvic_incidence, y=degree_spondylolisthesis))+
  geom_point(col='blue') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
  scale_y_continuous(breaks= seq(0, 800000, by=100000))
s2<-ggplot(data=dat, aes(x=lumbar_lordosis_angle, y=degree_spondylolisthesis))+
  geom_point(col='blue') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
  scale_y_continuous(breaks= seq(0, 800000, by=100000))
s3<-ggplot(data=dat, aes(x=sacral_slope, y=degree_spondylolisthesis))+
  geom_point(col='blue') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
  scale_y_continuous(breaks= seq(0, 800000, by=100000))
s4<-ggplot(data=dat, aes(x=pelvic_tilt.numeric, y=degree_spondylolisthesis))+
  geom_point(col='blue') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
  scale_y_continuous(breaks= seq(0, 800000, by=100000))
s5<-ggplot(data=dat, aes(x=pelvic_radius, y=degree_spondylolisthesis))+
  geom_point(col='blue') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
  scale_y_continuous(breaks= seq(0, 800000, by=100000))
grid.arrange(s1,s2,s3,s4,s5)

```
# Visualize us sacral_slope and pelvic_incidence   

```{r}


ggplot(data=dat, aes(x=sacral_slope, y=pelvic_incidence))+
  geom_point(col='blue') + geom_smooth(method = "lm", se=FALSE, color="black", aes(group=1)) +
  scale_y_continuous(breaks= seq(0, 800000, by=100000))

```

# Decision tree Analysis

```{r}

library(rpart.plot)
class.tree <- rpart(dat$class~.,data = dat,control = rpart.control(cp = 0.01))
rpart.plot(class.tree, 
           box.palette="GnBu",
           branch.lty=10, shadow.col="gray", nn=TRUE)

```

# Predictions (RandomForest vs Support Vector Machine (SVM) model vs Gradient Boosting Machine (GBM) model)

#  RandomForest
```{r}
caret_matrix <- train(x=dat[,1:6], y=dat[,7], data=dat, method='rf', trControl=trainControl(method="cv", number=5))
caret_matrix
```

# Support Vector Machine (SVM) model
```{r}
caret_svm <- train(x=dat[,1:6], y=dat[,7], data=dat, method='svmRadial', trControl=trainControl(method="cv", number=5))
caret_svm

```
#  Gradient Boosting Machine (GBM) model
```{r}
caret_boost <- train(class~pelvic_incidence+pelvic_tilt.numeric+lumbar_lordosis_angle+sacral_slope+
pelvic_radius+
  degree_spondylolisthesis, data=dat, method='gbm', preProcess= c('center', 'scale'), trControl=trainControl(method="cv", number=7), verbose=FALSE)
print(caret_boost)
```
# Correlation between algorithm
We are interested in correlation because uncorrelated models do better when they are assembled than correlated presentations.

# Combining Models
Ensembling is a technique of combining two or more algorithms of similar or dissimilar types called base learners. This is done to make a more robust system which incorporates the predictions from all the base learners


Now we can take all of these predictions into account while making the final decision. This will make our final decision more robust, accurate and less likely to be biased. The final decision would have been opposite if one of these traders would have made this decision alone.


# Majority vote ensemble for all the three models

Majority vote:Itâ€™s defined as taking the prediction with maximum vote / recommendation from multiple models predictions while predicting the outcomes of a classification problem.
 
```{r}


#recodify  our value
qualite<-c('Abnormal'=0,'Normal'=1)
dat$class<-as.factor(revalue(dat$class,qualite))
#Spliting training set into two parts based on outcome: 70% and 30%

index <- sample(2,nrow(dat),replace= TRUE,prob=c(0.7,0.3))
trainClean <- dat[index==1,]
testClean <- dat[index==2,]


# Random Forest model
caret_matrix <- train(x=trainClean[,1:6], y=trainClean[,7], data=trainClean, method='rf', trControl=trainControl(method="cv", number=5))
caret_matrix
solution_rf <- predict(caret_matrix, testClean)



# Support Vector Machine (SVM) model
caret_svm <- train(x=trainClean[,1:6], y=trainClean[,7], data=trainClean, method='svmRadial', trControl=trainControl(method="cv", number=5))
caret_svm
solution_svm <- predict(caret_svm, testClean)

#  Gradient Boosting Machine (GBM) model
caret_boost <- train(class~pelvic_incidence+pelvic_tilt.numeric+lumbar_lordosis_angle+sacral_slope+pelvic_radius+degree_spondylolisthesis, data=trainClean, method='gbm', preProcess= c('center', 'scale'), trControl=trainControl(method="cv", number=7), verbose=FALSE)
print(caret_boost)
solution_boost <- predict(caret_boost, testClean)


```

# Correlation between models
 We are interested in correlation because uncorrelated models do better when they are assembled than correlated presentations. 
 
```{r}

#adding model predictions to test dataframe
testClean$RF <- as.numeric(solution_rf)-1
testClean$SVM <- as.numeric(solution_svm)-1
testClean$Boost <- as.numeric(solution_boost)-1

#compose correlations plot
corrplot.mixed(cor(testClean[, c('RF', 'SVM', 'Boost')]), tl.col="black")


```

We only observe a correlation, and a very strong correlation between RF and GBM, this is probably not surprising because these two algorithms are of very similar nature but on the other hand the SVM is very different algorithm of these two of or can be the lack of ability to provide the degree of correlation between the two previous models. We will now move to the majority vote, let us note

If 0 or 1 model predicts 'Normal', the overall prediction will be 'Abnormal'

If 2 or 3 models predict 'Normal', the overall prediction will be 'Normal'
 
```{r}
testClean$Sum <- testClean$RF + testClean$SVM + testClean$Boost
testClean$Majority <- ifelse(testClean$Sum<=1, 0,1)

```
# KNN Model Analysis
```{r}
caret_knn <- train(class~., data=dat, method='knn', trControl=trainControl(method="cv", number=5),tuneLength = 20)
caret_knn

#train
caret_knn <- train(class~., data=trainClean, method='knn', trControl=trainControl(method="cv", number=5),tuneLength = 20)
caret_knn
```




# Conclusion
We analyze the Normal and Abnormal patient for different six biomechanical different biomechanicla desease.Found that 210 people are Abnormal and 100 people are normal.We have noticed that degree spondylolisthesis is the most important of the variables to explain the normal and abnormal of the patients.we analyze with decision tree ,boxplot.Also found the relationship between all the six different variables.There is correlation between degree spondylolisthesis and other variable.Also Noticed that high correlation between sacral_slope and pelvic_incidence.
Also analyze the different algorithm like  RandomForest,Support Vector Machine (SVM) model,Gradient Boosting Machine (GBM) modeland KNN model.




